# üåç Sistema Inteligente de Predicci√≥n y Preparaci√≥n de Pandemias
### End-to-End MLOps: Data Engineering, Supervised & Unsupervised Learning

![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Kedro](https://img.shields.io/badge/Kedro-Framework-FFC900?style=for-the-badge&logo=python&logoColor=black)
![Airflow](https://img.shields.io/badge/Apache%20Airflow-Orchestration-017EBA?style=for-the-badge&logo=apacheairflow&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Containerization-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/scikit--learn-ML-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white)

---

## üìñ Descripci√≥n del Proyecto

Este proyecto implementa una soluci√≥n completa de **Machine Learning y MLOps** dise√±ada para evaluar la resiliencia global ante crisis sanitarias. Utilizando una base de datos hist√≥rica masiva (2020-2023) con m√°s de **750,000 registros**, el sistema permite:

1.  **Diagnosticar** la capacidad de respuesta actual de un pa√≠s.
2.  **Predecir** su nivel de preparaci√≥n (`Low`, `Medium`, `High`) mediante modelos supervisados.
3.  **Segmentar** comportamientos globales para identificar patrones de vulnerabilidad mediante aprendizaje no supervisado.

El desarrollo sigue la metodolog√≠a **CRISP-DM** y abarca todo el ciclo de vida del dato, desde la ingenier√≠a bruta hasta la orquestaci√≥n automatizada.

---

## ‚öôÔ∏è Arquitectura y Tecnolog√≠as

El proyecto se sustenta en un pipeline modular orquestado:

| Componente | Tecnolog√≠a | Funci√≥n Principal |
|:---:|:---:|:---|
| **Core Framework** | **Kedro** | Estructura de nodos y pipelines reproducibles. |
| **Orquestaci√≥n** | **Apache Airflow** | Programaci√≥n y monitoreo de tareas (ETL + Training). |
| **Contenedores** | **Docker** | Aislamiento del entorno para garantizar la ejecuci√≥n en cualquier m√°quina. |
| **Versionado** | **DVC & Git** | Control de versiones de c√≥digo, datos y modelos. |
| **Modelado** | **Scikit-Learn / XGBoost** | Algoritmos de clasificaci√≥n, regresi√≥n y clustering. |

---

## üìä Evoluci√≥n del Proyecto (Fases)

### üîπ Fase 1: Ingenier√≠a de Datos (ETL)
* **Desaf√≠o:** Integrar 4 fuentes de datos dispares con alta tasa de nulidad y ruido.
* **Soluci√≥n:** Pipeline de limpieza automatizado.
* **Resultados:**
    * Procesamiento de **~750,000 registros** de 200+ pa√≠ses.
    * Creaci√≥n de **30-45 variables sint√©ticas** (Feature Engineering).
    * Reducci√≥n de valores nulos a <5% en el dataset anal√≠tico final.

### üîπ Fase 2: Modelos Supervisados (Clasificaci√≥n)
Se entrenaron y validaron 5 algoritmos para predecir el `Capacity Score` de los pa√≠ses.

| Modelo Evaluado | Accuracy | Tiempo Entr. | Veredicto |
|-----------------|----------|--------------|-----------|
| **Random Forest** | **99.79%** | 38s | üèÜ **Mejor Modelo (Batch)** por precisi√≥n absoluta. |
| **XGBoost** | 99.40% | **24s** | üöÄ **Mejor Modelo (Real-time)** por eficiencia/velocidad. |
| SVM | - | 52 min | Descartado por costo computacional. |
| Logistic Regression | 65.00% | R√°pido | Descartado por bajo rendimiento (Underfitting). |

### üîπ Fase 3: Aprendizaje No Supervisado (Clustering)
B√∫squeda de patrones latentes sin etiquetas predefinidas.
* **Reducci√≥n de Dimensionalidad (PCA):** Se comprimieron 81 variables a **20 componentes principales**, conservando el **95% de la varianza**.
* **Segmentaci√≥n (K-Means):** Se descubrieron **2 Arquetipos Globales** (Silhouette: 0.343):
    * **Cluster 0 (Alta Resiliencia):** Pa√≠ses con respuesta log√≠stica r√°pida y recursos financieros robustos.
    * **Cluster 1 (Vulnerabilidad Estructural):** Pa√≠ses dependientes de ayuda externa con retrasos cr√≠ticos en vacunaci√≥n.

---

## üìÇ Estructura del Repositorio

El proyecto sigue el est√°ndar de `Data Science Cookiecutter` adaptado a Kedro:

```text
prediccion-pandemias/
‚îú‚îÄ‚îÄ airflow/               # DAGs para orquestaci√≥n del pipeline
‚îÇ   ‚îî‚îÄ‚îÄ dags/ml_pipeline_master.py
‚îú‚îÄ‚îÄ conf/                  # Configuraciones (Cat√°logos de datos, par√°metros)
‚îú‚îÄ‚îÄ data/                  # Almacenamiento local (Ignorado por Git por seguridad)
‚îÇ   ‚îú‚îÄ‚îÄ 01_raw/            # Datos crudos inmutables
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ 07_model_output/   # Artefactos y reportes generados
‚îú‚îÄ‚îÄ notebooks/             # An√°lisis exploratorio y pruebas de concepto
‚îÇ   ‚îú‚îÄ‚îÄ 01_business_understanding.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_understanding.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_data_preparation.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_classification_analysis.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_unsupervised_learning_analysis.ipynb
‚îú‚îÄ‚îÄ src/                   # C√≥digo fuente productivo
‚îÇ   ‚îî‚îÄ‚îÄ pipelines/         # L√≥gica modular (ETL, Data Science, Clustering)
‚îú‚îÄ‚îÄ Dockerfile             # Definici√≥n de imagen para despliegue
‚îú‚îÄ‚îÄ docker-compose.yml     # Orquestaci√≥n de servicios
‚îî‚îÄ‚îÄ requirements.txt       # Dependencias del proyecto
